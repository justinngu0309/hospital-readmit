import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier, RandomForestClassifier
from imblearn.combine import SMOTEENN
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import cross_val_score
from sklearn.impute import KNNImputer

def train_model():
    # Load data
    print("Loading dataset...")
    data_path = r'/Users/justinnguyen0309/Downloads/diabetic_data.csv'
    new_data = pd.read_csv(data_path)
    print("Dataset shape: {}".format(new_data.shape))

    print("Sanitizing data...")
    new_data.replace('?', np.nan, inplace=True)
    new_data.drop_duplicates(inplace=True)

    print("Dropping irrelevant columns...")
    irrelevant_cols = ['encounter_id', 'patient_nbr', 'payer_code', 'weight', 'medical_specialty']
    new_data.drop(columns=irrelevant_cols, inplace=True)

    print("Converting binary columns...")
    binaryCols = ['change', 'diabetesMed', 'readmitted']
    for col in binaryCols:
        new_data[col] = new_data[col].apply(lambda x: 0 if x in ['No', 'NO'] else 1)

    print("Encoding categorical columns...")
    categoricalCols = ['max_glu_serum', 'A1Cresult']
    for col in categoricalCols:
        new_data[col + '_ind'] = new_data[col].map({'None': 0, 'Norm': 1, '>200': 2, '>7': 2}).fillna(0)

    print("Encoding 'age' column...")
    le = LabelEncoder()
    new_data['age_t'] = le.fit_transform(new_data['age'])

    print("Selecting numerical columns...")
    quantCols = new_data.select_dtypes(include=[np.number]).columns

    df_features = new_data[quantCols]
    print("Numerical features shape: {}".format(df_features.shape))

    print("Applying log transformation to skewed features...")
    transformCols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures',
                     'num_medications', 'number_outpatient', 'number_inpatient', 'number_emergency']
    df_log = df_features.copy()
    for feat in transformCols:
        df_log[feat] = np.log1p(df_features[feat])

    print("Applying KNN Imputation...")
    imputer = KNNImputer(n_neighbors=3)
    df_log[transformCols] = imputer.fit_transform(df_log[transformCols])
    X = df_log.drop(columns=['readmitted'], axis=1)
    y = df_log['readmitted']
    selected_features = X.columns.tolist()
    joblib.dump(selected_features, 'selected_features.pkl', protocol=3)
    print("Normalizing data...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    joblib.dump(scaler, 'scaler.pkl', protocol=3)

    print("Applying SMOTEENN to handle class imbalance...")
    smoteenn = SMOTEENN(random_state=123)
    X_resampled, y_resampled = smoteenn.fit_resample(X_scaled, y)
    print("Resampled dataset shape: {}".format(X_resampled.shape))

    # Train-test split (15% testing, 85% training)
    print("Splitting data into training and testing sets...")
    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.15, random_state=123)

    print("Defining models...")
    rf = RandomForestClassifier(
        n_estimators=150, max_depth=12, min_samples_split=4, min_samples_leaf=2,
        class_weight='balanced', random_state=123, n_jobs=-1
    )
    gb = GradientBoostingClassifier(n_estimators=150, learning_rate=0.1, max_depth=5, random_state=123)
    print("Training stacking ensemble model...")
    stacking_ensemble = StackingClassifier(
        estimators=[('rf', rf), ('gb', gb)],
        final_estimator=GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=4),
        cv=3, n_jobs=-1
    )

    stacking_ensemble.fit(X_train, y_train)
    joblib.dump(stacking_ensemble, 'stacking_ensemble_model.pkl', protocol=3)
    print("Evaluating stacking ensemble model...")
    y_test_pred = stacking_ensemble.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_test_pred)
    print("Stacking Ensemble Test Accuracy: {:.2f}%".format(test_accuracy * 100))
    print("Generating confusion matrix...")
    conf_matrix = confusion_matrix(y_test, y_test_pred)
    print(conf_matrix)

    print("Performing cross-validation on stacking ensemble model...")
    cv_scores = cross_val_score(stacking_ensemble, X_train, y_train, cv=3, scoring="accuracy", n_jobs=-1)
    print("Stacking Ensemble Cross-Validation Accuracy: {:.2f}% (+/- {:.2f}%)".format(cv_scores.mean() * 100, cv_scores.std() * 100))

def predict_readmission():
    print("Loading model and pre-processing tools...")
    model = joblib.load('stacking_ensemble_model.pkl')
    scaler = joblib.load('scaler.pkl')
    selected_features = joblib.load('selected_features.pkl')

    print("Please answer the following questions about your health: ")
    def ask_question(prompt, valid_range=None):
        while True:
            try:
                response = input(prompt).strip()
                if valid_range and response not in valid_range:
                    print("Invalid input. Please choose from {}.".format(valid_range))
                    continue
                return int(response) if response.isdigit() else response
            except ValueError:
                print("Invalid. Please enter a valid option.")

    change = ask_question("Have you experienced a change in your condition? (1 for yes, 0 for no): ", ['0', '1'])
    diabetesMed = ask_question("Are you taking diabetes medication? (1 for yes, 0 for no): ", ['0', '1'])
    readmitted = ask_question("Were you readmitted in the past? (1 for yes, 0 for no): ", ['0', '1'])
    max_glu_serum = ask_question("What is your maximum glucose serum level? (None/Norm/>200): ", ['None', 'Norm', '>200'])
    A1Cresult = ask_question("What is your A1C result? (None/Norm/>7): ", ['None', 'Norm', '>7'])
    age_group = ask_question("What is your age group? (0 for 0-10, 1 for 10-20, etc.): ")
    time_in_hospital = ask_question("How many days were you in the hospital? ")
    num_lab_procedures = ask_question("How many lab procedures were performed? ")
    num_procedures = ask_question("How many procedures were performed? ")
    num_medications = ask_question("How many medications were prescribed? ")
    number_outpatient = ask_question("How many outpatient visits did you have? ")
    number_inpatient = ask_question("How many inpatient visits did you have? ")
    number_emergency = ask_question("How many emergency visits did you have? ")
    max_glu_serum_map = {'None': 0, 'Norm': 1, '>200': 2}
    A1Cresult_map = {'None': 0, 'Norm': 1, '>7': 2}

    feature_vector = {
        'change': change,
        'diabetesMed': diabetesMed,
        'readmitted': readmitted,
        'max_glu_serum_ind': max_glu_serum_map[max_glu_serum],
        'A1Cresult_ind': A1Cresult_map[A1Cresult],
        'age_t': age_group,
        'time_in_hospital': np.log1p(time_in_hospital),
        'num_lab_procedures': np.log1p(num_lab_procedures),
        'num_procedures': np.log1p(num_procedures),
        'num_medications': np.log1p(num_medications),
        'number_outpatient': np.log1p(number_outpatient),
        'number_inpatient': np.log1p(number_inpatient),
        'number_emergency': np.log1p(number_emergency),
    }

    # Add missing features with default values
    for feature in selected_features:
        if feature not in feature_vector:
            feature_vector[feature] = 0  

    # Order the features according to the model's eval
    input_vector = np.array([feature_vector[feature] for feature in selected_features])

    # Scale the input
    input_vector_scaled = scaler.transform([input_vector])

    prediction = model.predict(input_vector_scaled)
    if prediction[0] == 1:
        print("The model predicts you are at risk of readmission.")
    else:
        print("The model predicts you are not at risk of readmission.")

train_model()
# predict_readmission()